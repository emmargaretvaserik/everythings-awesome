---
title: "Assignment 3 , Methods 3, 2024, autumn semester"
date: "2024-10-22"
output: html_document
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>


```{r}
library(reticulate)
print(conda_list()) #this should print the path to the conda environments

use_python("/opt/miniconda3/envs/methods3_2024/bin/python")
```

import the important packages
```{python}
import sklearn as sk
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
```


# Exercises and objectives

A) Load the magnetoencephalographic recordings and do some initial plots to understand the data  
B) Do logistic regression to classify pairs of PAS-ratings and all four-PAS-ratings 

REMEMBER: In your portfolio, make sure to include code that can reproduce the answers requested in the exercises below (__MAKE A KNITTED VERSION__). If it does not KNIT, it cannot be part of your portfolio

# EXERCISE A - Load the magnetoencephalographic recordings and do some initial plots to understand the data  

The files `megmag_data.npy` and `pas_vector.npy` can be downloaded here (http://laumollerandersen.org/data_methods_3/megmag_data.npy) and here (http://laumollerandersen.org/data_methods_3/pas_vector.npy)   

1) Load `megmag_data.npy` and call it `data` using `np.load`. You can use `join`, which can be imported from `os.path`, to create paths from different string segments  
    i. The data is a 3-dimensional array. The first dimension is number of repetitions of a visual stimulus , the second dimension is the number of sensors that record magnetic fields (in Tesla) that stem from neurons activating in the brain, and the third dimension is the number of time samples. How many repetitions, sensors and time samples are there?  
    ii. The time range is from (and including) -200 ms to (and including) 800 ms with a sample recorded every 4 ms. At time 0, the visual stimulus was briefly presented. Create a 1-dimensional array called `times` that represents this.  
    iii. Create the sensor covariance matrix $\Sigma_{XX}$: $$\Sigma_{XX} = \frac 1 N \sum_{i=1}^N XX^T$$ $N$ is the number of repetitions and $X$ has $s$ rows and $t$ columns (sensors and time), thus the shape is $X_{s\times t}$. Do the sensors pick up independent signals? (Use `plt.imshow` to plot the sensor covariance matrix)  
    iv. Make an average over the repetition dimension     using `np.mean` - use the `axis` argument. (The resulting array should have two dimensions  with sensor as the first and time as the second)  
    v. Plot the magnetic field (based on the average) as it evolves over time for each of the sensors (a line for each) (time on the x-axis and magnetic field on the y-axis). Add a horizontal line at $y = 0$ and a vertical line at $x = 0$ using `plt.axvline` and `plt.axhline`  
    vi. Find the maximal magnetic field in the average. Then use `np.argmax` and `np.unravel_index` to find the sensor that has the maximal magnetic field.  
    vii. Plot the magnetic field for each of the repetitions (a line for each) for the sensor that has the maximal magnetic field. Highlight the time point with the maximal magnetic field in the average (as found in A.1.v) using `plt.axvline`  
    viii. Describe in your own words how the response found in the average is represented in the single repetitions. But do make sure to use the concepts _signal_ and _noise_ and comment on any differences on the range of values on the y-axis  
 
 
 
 
##### MEEEEEEEEEEEEEEEEEEEEEEEEEEEE
2) Now load `pas_vector.npy` (call it `y`). PAS is the same as in Assignment 2, describing the clarity of the subjective experience the subject reported after seeing the briefly presented stimulus  
```{python}
file_path_data = os.path.expanduser('~/Documents/CogSci/Sem3/Methods3/megmag_data.npy') # Creating a file path to the npy file.
data = np.load(file_path_data) # Loading the file path to the variable

file_path = os.path.expanduser('~/Documents/CogSci/Sem3/Methods3/pas_vector.npy') # Creating a file path to the npy file.
y = np.load(file_path) # Loading the file path to the variable
```
    i. Which dimension in the `data` array does it have the same length as?  
```{python}
y = np.squeeze(y)
target_length = len(y)
print(target_length)

# The dimension of which it shares the same length is the number of repetitions.

```
    ii. Now make four averages (As in Exercise A.1.iv), one for each PAS rating, and plot the four time courses (one for each PAS rating) for the sensor found in Exercise A.1.vi
```{python}
# Creating a variable to store average time courses for each PAS rating
average_time_courses = {}

# Loop through each PAS rating (assuming ratings are 1, 2, 3, and 4)
for rating in range(1, 5):
    # Getting the indices of all occurrences of the PAS rating in y
    indices = np.where(y == rating)[0]
    
    # Select data for the chosen PAS rating across all repetitions and sensors
    selected_data = data[indices, :, :]
    
    # Choose a specific sensor index, e.g., sensor 0
    sensor_data = selected_data[:, 73, :]  # Selecting the time courses for sensor 73
    
    # Calculate the average time course for this sensor and PAS rating
    average_time_course = np.mean(sensor_data, axis=0)
    
    # Store the average time course in the dictionary
    average_time_courses[rating] = average_time_course

# Plotting the average time courses for each PAS rating
plt.figure(figsize=(12, 6))
for rating, time_course in average_time_courses.items():
    plt.plot(time_course, label=f'PAS Rating {rating}')

# Adding labels and legend
plt.title("Average Time Courses for Each PAS Rating (Sensor 74)")
plt.xlabel("Time Samples")
plt.ylabel("Magnetic Field (Tesla)")
plt.legend()
plt.show()


```
    iii. Notice that there are two early peaks (measuring visual activity from the brain), one before 200 ms and one around 250 ms. Describe how the amplitudes of responses are related to the four PAS-scores. Does PAS 2 behave differently than expected?  
```{python}
# Initial Peak (before 200 ms): At the first peak, the amplitudes vary slightly across the PAS scores. Notably, PAS 2 shows an unexpectedly high amplitude compared to PAS 1 and even PAS 3. This is surprising, as one would typically expect PAS 2 to have a lower amplitude than PAS 3 if the ratings are intended to show increasing strength of subjective experience.

# Second Peak (around 250 ms): In the second peak, amplitude differences across PAS scores are again visible. PAS 4 displays the highest response amplitude, which aligns with its rating as the strongest subjective experience. However, PAS 2 again shows an amplitude similar to or slightly higher than PAS 1 and PAS 3, which diverges from the expected pattern.

# PAS 2 behaves differently than expected, as it shows amplitudes similar to or greater than PAS 3 and even occasionally closer to PAS 4.
```




# EXERCISE B - Do logistic regression to classify pairs of PAS-ratings  

1) Now, we are going to do Logistic Regression with the aim of classifying the PAS-rating given by the subject  
    i. We'll start with a binary problem - create a new array called `data_1_2` that only contains PAS responses 1 and 2. Similarly, create a `y_1_2` for the target vector  
    ii. Scikit-learn expects our observations (`data_1_2`) to be in a 2d-array, which has samples (repetitions) on dimension 1 and features (predictor variables) on dimension 2. Our `data_1_2` is a three-dimensional array. Our strategy will be to collapse our two last dimensions (sensors and time) into one dimension, while keeping the first dimension as it is (repetitions). Use `np.reshape` to create a variable `X_1_2` that fulfils these criteria.  
    iii. Import the `StandardScaler` and scale `X_1_2`  
    iv. Do a standard `LogisticRegression` - can be imported from `sklearn.linear_model` - make sure there is no `penalty` applied  
    v. Use the `score` method of `LogisticRegression` to find out how many labels were classified correctly. Are we overfitting? Besides the score, what would make you suspect that we are overfitting?  
    vi. Now apply the _L1_ penalty instead, using the default C, - how many of the coefficients (`.coef_`) are non-zero after this?  
    vii. Create a new reduced $X$ that only includes the non-zero coefficients - show the covariance of the non-zero features; $X_{reduced}X_{reduced}^T$ . Plot the covariance of the features using `plt.imshow`. Compared to a covariance-plot where you do not use any penalties, do you see less covariance? (Ignore the absolute values, but look at the pattern)
  
2) Now, we are going to build better (more predictive) models by using cross-validation as an outcome measure    
    i. Import `cross_val_score` and `StratifiedKFold` from `sklearn.model_selection`  
    ii. To make sure that our training data sets are not biased to one target (PAS) or the other, create `y_1_2_equal`, which should have an equal number of each target. Create a similar `X_1_2_equal`. The function `equalize_targets_binary` in the code chunk associated with Exercise B.2.ii can be used. Remember to scale `X_1_2_equal`!  
    iii. Do cross-validation with 5 stratified folds doing standard `LogisticRegression` (See Exercise B.1.iv)  
    iv. Do L2-regularisation with the following `Cs=[1e5, 1e1, 1e-5]`. Use the same kind of cross-validation as in Exercise B.2.iii. In the best-scoring of these models, how many more/fewer predictions are correct (on average)?  
    v. Instead of fitting a model on all `n_sensors * n_samples` features, fit  a logistic regression (same kind as in Exercise B.2.iv (use the `C` that resulted in the best prediction)) for __each__ time sample and use the same cross-validation as in Exercise B.2.iii. What are the time points where classification is best? Make a plot with time on the x-axis and classification score on the y-axis with a horizontal line at the chance level (what is the chance level for this analysis?)  
    vi. Now do the same, but with L1 regression - set `C=1e-1` - what are the time points when classification is best? (make a plot)?  
    vii. Finally, fit the same models as in Exercise B.2.vi but now for `data_1_4` and `y_1_4` (create a data set and a target vector that only contains PAS responses 1 and 4). What are the time points when classification is best? Make a plot with time on the x-axis and classification score on the y-axis with a horizontal line at the chance level (what is the chance level for this analysis?)  
    viii. Is pairwise classification of subjective experience possible? Any surprises in the classification accuracies, i.e. how does the classification score for PAS 1 vs 4 compare to the classification score for PAS 1 vs 2?  
    
    
    
    
##### MEEEEEEEEEEEEEEEEEEEEEEEEEEEE
3) Do multinomial logistic regression
    i. First equalize the number of targets using the function associated with each PAS-rating using the function associated with Exercise B.3.i
```{python}
# Exercise B.3.i
def equalize_targets(data, y):
    np.random.seed(7) # Setting a random seed
    targets = np.unique(y)
    counts = list()
    indices = list()
    for target in targets:
        counts.append(np.sum(y == target))
        indices.append(np.where(y == target)[0])
    min_count = np.min(counts) # Checking the minimum number of counts per PAS rating
    first_choice = np.random.choice(indices[0], size=min_count, replace=False)
    second_choice = np.random.choice(indices[1], size=min_count, replace=False)
    third_choice = np.random.choice(indices[2], size=min_count, replace=False)
    fourth_choice = np.random.choice(indices[3], size=min_count, replace=False)
    
    new_indices = np.concatenate((first_choice, second_choice, # Collecting the indices choices.
                                 third_choice, fourth_choice))
    new_y = y[new_indices]
    new_data = data[new_indices, :, :]
    
    return new_data, new_y
  
equalized_data, equalized_y = equalize_targets(data,y)  # Creating new variables using the associated function to equalize.

```
    ii. Split the equalized data set (with all four ratings) into a training part and test part, where the test part is 30 % of the trials. Use `train_test_split` from `sklearn.model_selection`. Also standardise the data.
```{python}
# Importing the following packages for the rest of the exercise.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer
from sklearn.metrics import confusion_matrix
```

```{python}
def flatten_data(X): # A function to reshape the 3d array into a 2d so that we can transform it.
    return X.reshape(X.shape[0], -1)

X_train, X_test, y_train, y_test = train_test_split( # Creating training and test variables for each.
    equalized_data, equalized_y, test_size=0.3, random_state=1) # Using 30% of the data for tests.

pipe_n1 = Pipeline([
    ('reshape', FunctionTransformer(flatten_data)),  # Flatten the data to 2D model for standardization
    ('scl', StandardScaler()),  # Applying standardization
])

# Fitting the pipeline on training data
pipe_n1.fit(X_train, y_train)
```
    iii. Use the L2-regularisation chosen in Exercise B.2.iv (use the `C` that resulted in the best prediction) `fit`the training set and `predict` on the test set. This time your features are the number of sensors multiplied by the number of samples.  
```{python}

best_C = 0.1  # REPLACE WHEN GIVEN ACTUAL C VALUE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

# Flatten the data function
def flatten_data(X):
    return X.reshape(X.shape[0], -1)  # Reshape to [n_samples, n_features]

# Splitting the data into training and test.
X_train, X_test, y_train, y_test = train_test_split(
    equalized_data, equalized_y, test_size=0.3, random_state=1)

# Define the pipeline with L2-regularized Logistic Regression using the best predicted C value
pipe_n2 = Pipeline([
    ('reshape', FunctionTransformer(flatten_data)), # Flatten to 2D
    ('scl', StandardScaler()), # Standardize features
    ('pca', PCA(n_components=2)), # Principle Component Analysis with 2 components
    ('clf', LogisticRegression(C=best_C, penalty='l2', random_state=1))  # L2 regularization
])

# Fit the model on training data and predict on test data
pipe_n2.fit(X_train, y_train)

print('Training Accuracy: %.3f' % pipe_n2.score(X_train, y_train))
print('Test Accuracy: %.3f' % pipe_n2.score(X_test, y_test))
```
    iv. Create a _confusion matrix_. It is a 4x4 matrix. The row names and the column names are the PAS-scores. There will thus be 16 entries. The PAS1xPAS1 entry will be the number of actual PAS1, $y_{pas1}$ that were predicted as PAS1, $\hat y_{pas1}$. The PAS1xPAS2 entry will be the number of actual PAS1, $y_{pas1}$ that were predicted as PAS2, $\hat y_{pas2}$ and so on for the remaining 14 entries.  Plot the matrix
```{python}
# Fit the model on training data and predict on test data again
pipe_n2.fit(X_train, y_train)
y_pred = pipe_n2.predict(X_test)
# Creating the confusion matrix from the predicted data and test data.
confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)
print(confmat)

# Creating custom labels for the confusion matrix
pas_labels = ['PAS1', 'PAS2', 'PAS3', 'PAS4']
# Plotting a better looking confusion matrix.
fig, ax = plt.subplots(figsize=(3, 3))
ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(confmat.shape[0]):
  for j in range(confmat.shape[1]):
    ax.text(x=j, y=i,
            s=confmat[i, j],
            va='center', ha='center')

# Adding the custom labels to the axis.
ax.set_xticks(range(len(pas_labels)))
ax.set_xticklabels(pas_labels)
ax.set_yticks(range(len(pas_labels)))
ax.set_yticklabels(pas_labels)
# Adding heading labels on the plot and both axis.
plt.xlabel('Predicted PAS Score')
plt.ylabel('Actual PAS Score')
plt.title('Confusion Matrix of PAS Scores')
plt.show()
```
    v. Based on the confusion matrix, describe how ratings are misclassified and if that makes sense given that ratings should measure the strength/quality of the subjective experience. Is the classifier biased towards specific ratings?  
```{python}
# The classifier is bias towards a weaker rating in particular PAS2 as it under-predicts the PAS3 and 4 ratings whilst predicting the majority of experiences as a PAS2 rating. This makes sense as it is subjective experience and could be explained by an inherent overlap in the distinguishing parameters used to identify each level of experience, which would explain the difficulty the model had in identifying differences in level of subjective experience.
```










```{python, eval=FALSE}

# Exercise B.2.ii
def equalize_targets_binary(data, y):
    np.random.seed(7)
    targets = np.unique(y) ## find the number of targets
    if len(targets) > 2:
        raise NameError("can't have more than two targets")
    counts = list()
    indices = list()
    for target in targets:
        counts.append(np.sum(y == target)) ## find the number of each target
        indices.append(np.where(y == target)[0]) ## find their indices
    min_count = np.min(counts)
    # randomly choose trials
    first_choice = np.random.choice(indices[0], size=min_count, replace=False)
    second_choice = np.random.choice(indices[1], size=min_count,replace=False)
    
    # create the new data sets
    new_indices = np.concatenate((first_choice, second_choice))
    new_y = y[new_indices]
    new_data = data[new_indices, :, :]
    
    return new_data, new_y
# Exercise B.3.i

def equalize_targets(data, y):
    np.random.seed(7)
    targets = np.unique(y)
    counts = list()
    indices = list()
    for target in targets:
        counts.append(np.sum(y == target))
        indices.append(np.where(y == target)[0])
    min_count = np.min(counts)
    first_choice = np.random.choice(indices[0], size=min_count, replace=False)
    second_choice = np.random.choice(indices[1], size=min_count, replace=False)
    third_choice = np.random.choice(indices[2], size=min_count, replace=False)
    fourth_choice = np.random.choice(indices[3], size=min_count, replace=False)
    
    new_indices = np.concatenate((first_choice, second_choice,
                                 third_choice, fourth_choice))
    new_y = y[new_indices]
    new_data = data[new_indices, :, :]
    
    return new_data, new_y

```